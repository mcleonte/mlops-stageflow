# debug / dev / staging / prod
ENV_MODE=dev

PROJECT_ID=$PROJECT_ID

REGION="europe-central2"

APP_NAME="mlops-stageflow"
REPO_NAME=${APP_NAME}
BUCKET_NAME=${APP_NAME}
MODEL_NAME=${APP_NAME}

MODEL_VERSION_NUMBER=4
MODEL_VERSION_ALIAS=${ENV_MODE}-${MODEL_VERSION_NUMBER}

TRAINING_NAME=${MODEL_NAME}-${ENV_MODE}-${MODEL_VERSION_NUMBER}
MODEL_ID=${MODEL_NAME}-${ENV_MODE}
ENDPOINT_NAME=${MODEL_NAME}-${ENV_MODE}

BUCKET_PATH=/gcs/${BUCKET_NAME}
PREPROCESSORS_PATH=${BUCKET_PATH}/preprocessors
DATA_PATH=${BUCKET_PATH}/data
MODEL_PATH=/gcs/${BUCKET_NAME}/models/${MODEL_VERSION_ALIAS}/model
BASE_OUTPUT_DIR=gs://${BUCKET_NAME}/models/${MODEL_VERSION_ALIAS}

STAGING_TRAINING_MACHINE_TYPE=n1-standard-16 # sample data only
STAGING_INFERENCE_MACHINE_TYPE=n1-standard-8 # test requests only

PROD_TRAINING_MACHINE_TYPE=n1-standard-64
PROD_INFERENCE_MACHINE_TYPE=n1-standard-32

CUSTOM_IMAGE_ROOT_URI=${REGION}-docker.pkg.dev/${PROJECT_ID}/${REPO_NAME}/${REPO_NAME}
TRAINING_IMAGE_URI=${CUSTOM_IMAGE_ROOT_URI}-training:${MODEL_VERSION_ALIAS}
INFERENCE_IMAGE_URI=${CUSTOM_IMAGE_ROOT_URI}-inference:${MODEL_VERSION_ALIAS}
API_ENDPOINT=${REGION}-aiplatform.googleapis.com

PORT=80
PREDICT_ROUTE=/predict
EVAL_ROUTE=/evaluate
HEALTH_ROUTE=/healthcheck

# dev dataset
KAGGLE_DATASET="shashwatwork/consume-complaints-dataset-fo-nlp"

# tensorflow log level
TF_CPP_MIN_LOG_LEVEL=2

# range (inclusive) of n-gram sizes for tokenizing text
NGRAM_RANGE=(1,2)

# max number of features
TOP_K=20000

# 'word' or 'char' n-grams
TOKEN_MODE="word"

# discard tokens that appears only once
MIN_DOCUMENT_FREQUENCY=2

# random seed for data split
SPLIT_SEED=1

BATCH_SIZE=128
